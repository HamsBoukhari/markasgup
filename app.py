# Importing necessary libraries 
import streamlit as st  # Streamlit for creating a web-based application
from transformers import GPT2Tokenizer, GPT2LMHeadModel  # Libraries for tokenization and GPT-2 model
import torch  # PyTorch for deep learning operations
import re  # Regular expressions for text pattern matching and manipulation
import xmltodict  # For parsing and un-parsing XML data

# Function to initialize and cache tokenizer and models, allowing modifications to cached data
@st.cache(allow_output_mutation=True)
def get_model():
    # Load the tokenizer for the distilgpt2 model
    tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')
    # Set the pad token to be the end-of-sequence (EOS) token
    tokenizer.pad_token = tokenizer.eos_token
    # Load two pre-trained GPT-2 models from specific paths
    model1 = GPT2LMHeadModel.from_pretrained("hams2/markasgup1")
    model2 = GPT2LMHeadModel.from_pretrained("hams2/markasgup2")
    # Return the tokenizer and both models
    return tokenizer, model1, model2

# Retrieve the cached tokenizer and the two pre-trained GPT-2 models
tokenizer, model1, model2 = get_model()

# Set the title for the Streamlit app
st.title('Mark As Give Up')

# User input areas for trade message and SGW operation 
trade_msg = st.text_area('Trade Message')  # Text area for trade message input
sgw_op = st.text_area('SGW Operation')  # Text area for SGW operation input
# Button to trigger the prediction
button = st.button("Predict")

# If both text areas have input and the button is clicked, process the inputs
if (trade_msg and sgw_op) and button:
    try:
        # Remove newline characters from inputs
        trade_msg1 = trade_msg.replace('\n', '')
        sgw_op1 = sgw_op.replace('\n', '')
        # Concatenate the cleaned strings into a single input sequence
        input_seq = trade_msg1 + ' ' + sgw_op1
        
        # Clean the sequence by removing specific characters (<, \ ,", /) using regex
        pattern = r'[<\"/]'
        cleaned_seq1 = re.sub(pattern, '', input_seq)
        # Replace ">" with a space
        seq = cleaned_seq1.replace('>', ' ')
        
        # Set the first model to evaluation mode 
        model1.eval()
        
        # Encode the sequence into input IDs for the pre-trained GPT-2 models
        input_ids = tokenizer.encode(seq, return_tensors='pt')
        
        # Generate output from the first pre-trained GPT-2 model, specifying max length and padding token
        output1 = model1.generate(
            input_ids, 
            max_length=1000, 
            num_return_sequences=1, 
            pad_token_id=tokenizer.eos_token_id  # Use EOS token for padding
        )
        
        # Decode the generated output from the first pre-trained GPT-2 model
        decoded_output1 = tokenizer.decode(output1[0], skip_special_tokens=True)
        
        # Extract the generated output without the initial sequence
        output_sequence1 = decoded_output1[len(seq):].strip()
        
        # Parse the original trade message and the generated output from the first model into dictionaries
        trade_msg_dict = xmltodict.parse(trade_msg)  # Original trade message in dictionary form
        output_sequence_dict1 = xmltodict.parse(output_sequence1)  # Generated output from the first model in dictionary form
        
        # Compare and align 'MtchID' in the original trade message and the output from the first model
        match_id_value1 = trade_msg_dict['TrdCaptRpt']['@MtchID']
        match_id_value2 = output_sequence_dict1['TrdCaptRpt']['@MtchID']
        if match_id_value1 != match_id_value2:
            output_sequence_dict1['TrdCaptRpt']['@MtchID'] = match_id_value1
        
        # Compare and align 'TrdID' in the original trade message and the output from the first model
        trd_id_value1 = trade_msg_dict['TrdCaptRpt']['@TrdID']
        trd_id_value2 = output_sequence_dict1['TrdCaptRpt']['@TrdID']
        if trd_id_value1 != trd_id_value2:
            output_sequence_dict1['TrdCaptRpt']['@TrdID'] = trd_id_value1
        
        # Convert the updated dictionary from the first model back into XML format
        modified_ccp_message1 = xmltodict.unparse(output_sequence_dict1, pretty=False)
        
        # Remove XML declaration if it exists at the start of the first model's message
        if modified_ccp_message1.startswith("<?xml"):
            modified_ccp_message1 = modified_ccp_message1.split("?>", 1)[1].strip()
        
        # Remove newline and tab characters from the XML output from the first model
        modified_ccp_message1 = modified_ccp_message1.replace("\n", "").replace("\t", "")
        
        # Display the modified message generated by the first model in the Streamlit app
        st.write("CCP Message 1: ", modified_ccp_message1) 
        
        # Set the second model to evaluation mode 
        model2.eval()
        
        # Generate output from the second pre-trained GPT-2 model with the same input IDs
        output2 = model2.generate(
            input_ids, 
            max_length=1000, 
            num_return_sequences=1, 
            pad_token_id=tokenizer.eos_token_id  # Use EOS token for padding
        )
        
        # Decode the generated output from the second model
        decoded_output2 = tokenizer.decode(output2[0], skip_special_tokens=True)
        
        # Remove the initial input sequence from the output of the second model
        output_sequence2 = decoded_output2[len(seq):].strip()
        
        # Parse the generated output from the second model into a dictionary
        output_sequence_dict2 = xmltodict.parse(output_sequence2)  
    
        # Convert the updated dictionary from the second model back into XML format
        modified_ccp_message2 = xmltodict.unparse(output_sequence_dict2, pretty=False)
    
        # Remove XML declaration from the second model's message, if it exists
        if modified_ccp_message2.startswith("<?xml"):
            modified_ccp_message2 = modified_ccp_message2.split("?>", 1)[1].strip()
        
        # Remove newline and tab characters from the XML output from the second model
        modified_ccp_message2 = modified_ccp_message2.replace("\n", "").replace("\t", "")
        
        # Display the modified message generated by the second model in the Streamlit app
        st.write("CCP Message 2: ", modified_ccp_message2) 
        
    except Exception as e:
        # If an error occurs, display an error message in the Streamlit app
        st.write("There is an error in generating CCP Messages. Please verify the Trade Message and the SGW Operation")
    
